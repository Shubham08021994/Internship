{
 "cells": [
  {
   "cell_type": "raw",
   "id": "61f254a9",
   "metadata": {},
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e5632",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "\n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "dd0eb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let import the required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d982dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "2880ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "1400fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation as required in the question\n",
    "\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div[1]/input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "a5090fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location as required in the question\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "225ee603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "0646fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "bdebb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "d0d1cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "01c29b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "6d9da166",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "25dc188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#let check the length of each required data\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "268bc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data into dataframe\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Experence_required':experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "8697d367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experence_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programmer / Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Frost &amp; Sullivan</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Python/Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>iMindYourBusiness</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate opening For Data Analyst @ Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                        HCL hiring For Data Analyst   \n",
       "2                          Programmer / Data Analyst   \n",
       "3      Data Analyst - Python/Artificial Intelligence   \n",
       "4                              Customer Data Analyst   \n",
       "5                                   Sr. Data Analyst   \n",
       "6                    Data Analyst - Decision Science   \n",
       "7     Immediate opening For Data Analyst @ Bangalore   \n",
       "8                             Associate Data Analyst   \n",
       "9                             Associate Data Analyst   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "2  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                          Bangalore/Bengaluru, Pune   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              Company_name Experence_required  \n",
       "0                                TeamLease            5-8 Yrs  \n",
       "1                         HCL Technologies            3-8 Yrs  \n",
       "2                         Frost & Sullivan            3-7 Yrs  \n",
       "3                        iMindYourBusiness            0-2 Yrs  \n",
       "4                                   Oracle            1-3 Yrs  \n",
       "5  Global Indian School Education Services           6-11 Yrs  \n",
       "6                  Jana Small Finance Bank            3-8 Yrs  \n",
       "7                                TeamLease            4-6 Yrs  \n",
       "8                                    Optum            2-7 Yrs  \n",
       "9                                    Optum            1-4 Yrs  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the data into dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c02e110",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba1d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let import the required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a0b636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4d7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249f9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation \"Data Scientist\" as required in the question\n",
    "\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div[1]/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5895437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location as required in the question\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2509b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86096c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fdbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job title\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c31f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992852d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c39f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#let check the length of each required data\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abaa0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data into dataframe\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae4323fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>upGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Gurgaon/Gurugram</td>\n",
       "      <td>ZS Associates India Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Nagpur</td>\n",
       "      <td>GlobalLogic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5                            Data Science Consultant   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                  Lead ML Scientist   \n",
       "9                      Tcs Hiring For Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "1                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "5        Bangalore/Bengaluru, Pune, Gurgaon/Gurugram   \n",
       "6                 Bangalore/Bengaluru, Noida, Nagpur   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                        Bangalore/Bengaluru, Mumbai   \n",
       "9   Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "\n",
       "                                  Company_name  \n",
       "0                                Tech Mahindra  \n",
       "1                                   CitiusTech  \n",
       "2                                    Accenture  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                                       upGrad  \n",
       "5                  ZS Associates India Pvt Ltd  \n",
       "6                                  GlobalLogic  \n",
       "7                                  GlobalLogic  \n",
       "8                            Fractal Analytics  \n",
       "9              TATA CONSULTANCY SERVICES (TCS)  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0245fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbadb70",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b77006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let import the required libraries first:\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eae8aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75e85eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3148c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation \"Data Scientist\" as required in the question\n",
    "\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div[1]/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "292bacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location as required in the question\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9f66b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5d33931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the salary filter\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5ae34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the location filter\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[13]/div[2]/div[3]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08a55b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2cb0edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job title\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76e476c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job location\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c97c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping company name\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "842ab9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping experience required\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c4c30ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#let check the length of each required data\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aca88423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data into dataframe\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Experence_required':experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0375da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experence_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>4i Odc</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist, Associate</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Job_title  \\\n",
       "0                         Data Scientist   \n",
       "1        DigitalBCG GAMMA Data Scientist   \n",
       "2                         Data Scientist   \n",
       "3    Data Scientist / Chat-bot Developer   \n",
       "4                    Lead Data Scientist   \n",
       "5  Data Scientist - Predictive Analytics   \n",
       "6      Data Scientist - Engine Algorithm   \n",
       "7                         Data Scientist   \n",
       "8                         Data Scientist   \n",
       "9              Data Scientist, Associate   \n",
       "\n",
       "                                        Job_location             Company_name  \\\n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru              GlobalLogic   \n",
       "1                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "2                                   Gurgaon/Gurugram                    Optum   \n",
       "3  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             Big Seo Buzz   \n",
       "4         Noida(Sector-59 Noida)\\n(WFH during Covid)  R Systems International   \n",
       "5  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...             Confidential   \n",
       "6  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...             Primo Hiring   \n",
       "7                                   Gurgaon/Gurugram           Feedback Infra   \n",
       "8                                              Noida                   4i Odc   \n",
       "9                                        Delhi / NCR            NatWest Group   \n",
       "\n",
       "  Experence_required  \n",
       "0           8-10 Yrs  \n",
       "1            2-5 Yrs  \n",
       "2            2-7 Yrs  \n",
       "3            3-7 Yrs  \n",
       "4           7-10 Yrs  \n",
       "5            1-6 Yrs  \n",
       "6            1-3 Yrs  \n",
       "7            2-4 Yrs  \n",
       "8            2-4 Yrs  \n",
       "9            2-7 Yrs  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82429f35",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "1. Brand\n",
    "\n",
    "2. Product Description\n",
    "\n",
    "3. Price\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "\n",
    "1.Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "\n",
    "2.Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "\n",
    "3.After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "\n",
    "4.After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it.\n",
    "\n",
    "5.Now scrape data from this page as usual\n",
    "\n",
    "6.Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3aecd572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let import the required libraries first:\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d70dbcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0dd9e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onpening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "31ad98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “sunglasses” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9166fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the search buttone\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2e4ac257",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "09807cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:Brand.append(i.text)\n",
    "    \n",
    "    product_des = driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in product_des:Product_Description.append(i.text)    \n",
    "    \n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in price:Price.append(i.text)\n",
    "    \n",
    "time.sleep(3)        \n",
    "        \n",
    "        \n",
    "nxt_button=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5a208dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "74b88195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (60)</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>Polarized, UV Protection, Mirrored, Gradient R...</td>\n",
       "      <td>₹476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>Polarized Round Sunglasses (48)</td>\n",
       "      <td>₹209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Spectacle Sunglasses (Free Size)</td>\n",
       "      <td>₹319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (62)</td>\n",
       "      <td>₹307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Wayfarer Sunglasses (61)</td>\n",
       "      <td>₹559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product_Description Price\n",
       "0        ROYAL SON         UV Protection Retro Square Sunglasses (60)  ₹479\n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹319\n",
       "2     CRYSTAL CART  Polarized, UV Protection, Mirrored, Gradient R...  ₹476\n",
       "3         Fastrack        UV Protection Shield Sunglasses (Free Size)  ₹719\n",
       "4        Rich Club                    Polarized Round Sunglasses (48)  ₹209\n",
       "..             ...                                                ...   ...\n",
       "95  ROZZETTA CRAFT     UV Protection Spectacle Sunglasses (Free Size)  ₹319\n",
       "96           NuVew               UV Protection Sports Sunglasses (62)  ₹307\n",
       "97       New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹189\n",
       "98  ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...  ₹279\n",
       "99       ROYAL SON  Polarized, UV Protection Wayfarer Sunglasses (61)  ₹559\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets  make dataframe from the scraped data\n",
    "\n",
    "df = pd.DataFrame({'Brand': Brand,'Product_Description':Product_Description,'Price':Price})\n",
    "\n",
    "df.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be2422",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button.\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bae4fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let import the required libraries first:\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8ffaf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "daf18e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2f6097f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “iphone 11” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c3fe46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "390ebdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the \"APPLE iPhone 11 (White, 128 GB)\"\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[4]/div/div/div/a/div[2]/div[1]/div[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2d9c5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5aa6743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    rating=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating:Rating.append(i.text)\n",
    "        \n",
    "    summary=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in summary:Review_summary.append(i.text)\n",
    "    \n",
    "    review=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review:Full_review.append(i.text)           \n",
    "        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ea4e9445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fcfc1bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c63240bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rating, Review_summary, Full_review]\n",
       "Index: []"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets  make dataframe from the scraped data\n",
    "\n",
    "df = pd.DataFrame({'Rating': Rating,'Review_summary':Review_summary,'Full_review':Full_review})\n",
    "\n",
    "df.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e8172e",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "    \n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e50c0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbd9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02df2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59b78df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “iphone 11” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8114f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf14e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d9ce15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    product_des = driver.find_elements(By.XPATH,\"//div[@class='_2B099V']/a[1]\")\n",
    "    for i in product_des:Product_Description.append(i.text)\n",
    "   \n",
    "    brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:Brand.append(i.text)\n",
    "      \n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in price:Price.append(i.text)\n",
    "                   \n",
    "nxt_button=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce8e8a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f13deff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIRBELL</td>\n",
       "      <td>Sneakers For Men Sneakers For Men</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Black Lightweight Casual Trendy Sneaker For Me...</td>\n",
       "      <td>₹434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KNIGHT WALKERS</td>\n",
       "      <td>Womens Loire Premium Casual Sneakers For Women</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product_Description Price\n",
       "0          AIRBELL                  Sneakers For Men Sneakers For Men  ₹479\n",
       "1          Numenzo  Black Lightweight Casual Trendy Sneaker For Me...  ₹434\n",
       "2           Shozie                                   Sneakers For Men  ₹389\n",
       "3           Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...  ₹629\n",
       "4             aadi                                   Sneakers For Men  ₹279\n",
       "..             ...                                                ...   ...\n",
       "95        ASTEROID  Original Luxury Branded Fashionable Men's Casu...  ₹449\n",
       "96          Shozie                                   Sneakers For Men  ₹348\n",
       "97  KNIGHT WALKERS     Womens Loire Premium Casual Sneakers For Women  ₹799\n",
       "98       Deals4you                                 Sneakers For Women  ₹297\n",
       "99       SCATCHITE                          Sneakers Sneakers For Men  ₹360\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['Brand']=Brand\n",
    "data['Product_Description']=Product_Description\n",
    "data['Price']=Price\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396d3bc",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bcfb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "751d2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "287782d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart website on automated chrome window\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ae06b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_price=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]\")\n",
    "filter_price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8b99cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_black=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "filter_black.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "43a606c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Shoe_Brand = []\n",
    "Shoe_Description = []\n",
    "Shoe_Price= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3c412143",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    \n",
    "    brand = driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in brand:Shoe_Brand.append(i.text)\n",
    "        \n",
    "    product_des = driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in product_des:Shoe_Description.append(i.text)\n",
    "        \n",
    "    price = driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in price:Shoe_Price.append(i.text)\n",
    "                   \n",
    "nxt_button=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]') \n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23606bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150 150\n"
     ]
    }
   ],
   "source": [
    "print(len(Shoe_Brand),len(Shoe_Description),len(Shoe_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "91a3a36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe_Brand</th>\n",
       "      <th>Shoe_Description</th>\n",
       "      <th>Shoe_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Leather Block Pumps with Buckles</td>\n",
       "      <td>Rs. 7693Rs. 10990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7693Rs. 10990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Leather Trainers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 9599Rs. 15999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Solid Leather Sneakers</td>\n",
       "      <td>Rs. 9499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Stiletto Sandals with Buckles</td>\n",
       "      <td>Rs. 8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Steve Madden</td>\n",
       "      <td>Women Woven Design Sneakers</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men Gel Flux 6 Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Shoe_Brand                       Shoe_Description  \\\n",
       "0   ROSSO BRUNELLO                    Men Leather Loafers   \n",
       "1             Geox       Leather Block Pumps with Buckles   \n",
       "2             Geox                    Men Leather Loafers   \n",
       "3   ROSSO BRUNELLO                    Men Leather Loafers   \n",
       "4             Puma                Unisex Leather Trainers   \n",
       "..             ...                                    ...   \n",
       "95            ALDO                    Men Leather Loafers   \n",
       "96            Geox             Men Solid Leather Sneakers   \n",
       "97         Saint G  Leather Stiletto Sandals with Buckles   \n",
       "98    Steve Madden            Women Woven Design Sneakers   \n",
       "99           ASICS           Men Gel Flux 6 Running Shoes   \n",
       "\n",
       "                    Shoe_Price  \n",
       "0                    Rs. 11999  \n",
       "1   Rs. 7693Rs. 10990(30% OFF)  \n",
       "2   Rs. 7693Rs. 10990(30% OFF)  \n",
       "3                    Rs. 10999  \n",
       "4                     Rs. 7999  \n",
       "..                         ...  \n",
       "95  Rs. 9599Rs. 15999(40% OFF)  \n",
       "96                    Rs. 9499  \n",
       "97                    Rs. 8500  \n",
       "98                    Rs. 8499  \n",
       "99                    Rs. 7999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['Shoe_Brand']=Shoe_Brand\n",
    "data['Shoe_Description']=Shoe_Description\n",
    "data['Shoe_Price']=Shoe_Price\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648ba1c",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6216ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e393ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e83f2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart website on automated chrome window\n",
    "driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ef31ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Laptop” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a20bda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “laptop” and click search button \n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2280f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “laptop” and click search button \n",
    "\n",
    "filter_CPU=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span/a/span\")\n",
    "filter_CPU.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "652bbe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Ratings = []\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f428d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_title= driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in product_title:Title.append(i.text)\n",
    "        \n",
    "product_rating = driver.find_elements(By.XPATH,'//span[@class=\"a-size-base s-underline-text\"]')\n",
    "for i in product_rating:Ratings.append(i.text)\n",
    "        \n",
    "product_price = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in product_price:Price.append(i.text)\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "20d51fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8be30f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>76</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td>83</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>8</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>60</td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>27</td>\n",
       "      <td>92,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>3</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DELL Alienware x14 Gaming Laptop, Intel i7-127...</td>\n",
       "      <td>4</td>\n",
       "      <td>2,00,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td>89</td>\n",
       "      <td>1,06,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...</td>\n",
       "      <td>28</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td>4</td>\n",
       "      <td>1,26,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...      76    84,990\n",
       "1  Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...      83    99,990\n",
       "2  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...       8    82,990\n",
       "3  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....      60    80,990\n",
       "4  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...      27    92,200\n",
       "5  Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...       3    94,990\n",
       "6  DELL Alienware x14 Gaming Laptop, Intel i7-127...       4  2,00,490\n",
       "7  Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...      89  1,06,999\n",
       "8  ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...      28  1,09,990\n",
       "9  ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...       4  1,26,990"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['Title']=Title\n",
    "data['Ratings']=Ratings\n",
    "data['Price']=Price\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e47a96",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida  location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4acd0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9735c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e6a9b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3c029e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “laptop” and click search button \n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "363b1b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Laptop” and click search button \n",
    "\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5ce08635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “laptop” and click search button \n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fe28aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i')\n",
    "search_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6f5c9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Laptop” and click search button \n",
    "\n",
    "enter_location=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "enter_location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "04cd0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_Noida=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "filter_Noida.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c4f6b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "job_posted = []\n",
    "company_rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a3fb7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name= driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]')\n",
    "for i in name:company_name.append(i.text)\n",
    "        \n",
    "posted = driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]')\n",
    "for i in posted:job_posted.append(i.text)\n",
    "        \n",
    "rating = driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]')\n",
    "for i in rating:company_rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "121ce322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4d ago',\n",
       " '2d ago',\n",
       " '4d ago',\n",
       " '2d ago',\n",
       " '31d ago',\n",
       " '24d ago',\n",
       " '26d ago',\n",
       " '1mon ago',\n",
       " '9d ago',\n",
       " '17d ago']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posted=job_posted[::2]\n",
    "posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "309e4710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(company_name),len(posted),len(company_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a9a63d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>company_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY GDS</td>\n",
       "      <td>4d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLOBALLOGIC INDIA PRIVATE LIMITED</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>31d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>24d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>26d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>One97 Communications Limited</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     company_name job_posted company_rating\n",
       "0  Optum Global Solutions (India) Private Limited     4d ago            4.1\n",
       "1  BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED     2d ago            4.3\n",
       "2                                          EY GDS     4d ago            3.8\n",
       "3               GLOBALLOGIC INDIA PRIVATE LIMITED     2d ago            4.0\n",
       "4                         CBRE South Asia Pvt Ltd    31d ago            4.3\n",
       "5                   GENPACT India Private Limited    24d ago            4.0\n",
       "6                                         Genpact    26d ago            4.0\n",
       "7        Ericsson India Global Services Pvt. Ltd.   1mon ago            4.3\n",
       "8                         Dew Solutions Pvt. Ltd.     9d ago            4.3\n",
       "9                    One97 Communications Limited    17d ago            3.8"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['company_name']=company_name\n",
    "data['job_posted']=posted\n",
    "data['company_rating']=company_rating\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f2e67",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. \n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "87865f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "db2c8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets connect with web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Chrome driver\\Chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "1a1f1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the ambitionbox website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "34f89996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select \"salary\" option\n",
    "\n",
    "Click_on_salary=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span')\n",
    "Click_on_salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "079a6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select \"salary\" option\n",
    "\n",
    "Click_on_browse_salary=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/a')\n",
    "Click_on_browse_salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "cfddca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Data Scientist”  \n",
    "\n",
    "designation=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a2b83040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Data Scientist” and click search button \n",
    "\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "3fed3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_name = []\n",
    "Total_Salary_Records = []\n",
    "Average_salary = []\n",
    "Minimum_salary = []\n",
    "Maximum_salary = []\n",
    "Experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "df54406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in name:Company_name.append(i.text.split(\"\\n\")[0])\n",
    "        \n",
    "record = driver.find_elements(By.XPATH,'//span[@class=\"datapoints\"]')\n",
    "for i in record:Total_Salary_Records.append(i.text)\n",
    "        \n",
    "avg_salary = driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in avg_salary:Average_salary.append(i.text)\n",
    "\n",
    "min_salary = driver.find_elements(By.XPATH,'//div[@class=\"salary-values\"]')\n",
    "for i in min_salary:Minimum_salary.append(i.text.split(\"\\n\")[0])\n",
    "    \n",
    "max_salary = driver.find_elements(By.XPATH,'//div[@class=\"salary-values\"]')\n",
    "for i in max_salary:Maximum_salary.append(i.text.split(\"\\n\")[1])\n",
    "\n",
    "exp_req = driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for i in exp_req:Experience_required.append(i.text.split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3e5dc3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Walmart',\n",
       " 'Ab Inbev',\n",
       " 'Optum',\n",
       " 'ZS',\n",
       " 'Fractal Analytics',\n",
       " 'Tiger Analytics',\n",
       " 'Sigmoid Analytics',\n",
       " 'Legato Health Technologies',\n",
       " 'HSBC',\n",
       " 'Tredence']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_name=Company_name[0:10]\n",
    "Company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "145de236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Check length \n",
    "\n",
    "print(len(Company_name),len(Total_Salary_Records),len(Average_salary),len(Minimum_salary),len(Maximum_salary),len(Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "417f3d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Total_Salary_Records</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Minimum_Salary</th>\n",
       "      <th>Maximum_Salary</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>(based on 23 salaries)</td>\n",
       "      <td>₹ 32.3L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience (based on 23 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>(based on 57 salaries)</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>2-4 yrs experience (based on 57 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>(based on 49 salaries)</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience (based on 49 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>(based on 34 salaries)</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience (based on 34 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>(based on 115 salaries)</td>\n",
       "      <td>₹ 15.4L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience (based on 115 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>(based on 68 salaries)</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience (based on 68 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>(based on 10 salaries)</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>1 yr experience (based on 10 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>(based on 11 salaries)</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience (based on 11 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>(based on 10 salaries)</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>4 yrs experience (based on 10 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>(based on 14 salaries)</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience (based on 14 salaries)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company_name     Total_Salary_Records Average_Salary  \\\n",
       "0                     Walmart   (based on 23 salaries)        ₹ 32.3L   \n",
       "1                    Ab Inbev   (based on 57 salaries)        ₹ 19.9L   \n",
       "2                       Optum   (based on 49 salaries)        ₹ 16.4L   \n",
       "3                          ZS   (based on 34 salaries)        ₹ 15.8L   \n",
       "4           Fractal Analytics  (based on 115 salaries)        ₹ 15.4L   \n",
       "5             Tiger Analytics   (based on 68 salaries)        ₹ 14.7L   \n",
       "6           Sigmoid Analytics   (based on 10 salaries)        ₹ 14.7L   \n",
       "7  Legato Health Technologies   (based on 11 salaries)        ₹ 14.5L   \n",
       "8                        HSBC   (based on 10 salaries)        ₹ 14.0L   \n",
       "9                    Tredence   (based on 14 salaries)        ₹ 13.9L   \n",
       "\n",
       "  Minimum_Salary Maximum_Salary                         Experience_required  \n",
       "0        ₹ 25.0L        ₹ 45.0L   3-4 yrs experience (based on 23 salaries)  \n",
       "1        ₹ 15.0L        ₹ 26.0L   2-4 yrs experience (based on 57 salaries)  \n",
       "2        ₹ 11.0L        ₹ 22.6L   2-4 yrs experience (based on 49 salaries)  \n",
       "3        ₹ 11.0L        ₹ 22.0L   1-2 yrs experience (based on 34 salaries)  \n",
       "4         ₹ 9.0L        ₹ 23.0L  2-4 yrs experience (based on 115 salaries)  \n",
       "5         ₹ 9.0L        ₹ 20.0L   2-4 yrs experience (based on 68 salaries)  \n",
       "6        ₹ 12.7L        ₹ 19.7L      1 yr experience (based on 10 salaries)  \n",
       "7        ₹ 11.0L        ₹ 20.0L     4 yrs experience (based on 11 salaries)  \n",
       "8        ₹ 12.0L        ₹ 18.0L     4 yrs experience (based on 10 salaries)  \n",
       "9         ₹ 8.8L        ₹ 17.5L     3 yrs experience (based on 14 salaries)  "
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "\n",
    "df = pd.DataFrame({'Company_name':Company_name,'Total_Salary_Records':Total_Salary_Records,'Average_Salary':Average_salary,'Minimum_Salary':Minimum_salary,'Maximum_Salary':Maximum_salary,'Experience_required':Experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b9b0035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
